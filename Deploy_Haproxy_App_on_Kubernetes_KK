Deploy Haproxy App on Kubernetes

The Nautilus project team needs to setup a HaProxy app on Kubernetes cluster. 
In the recent meeting they have discussed all requirements and implementation details how they will proceed. Below you can find more details and can proceed accordingly:
1.	Create a namespace haproxy-controller-datacenter.
2.	Create a ServiceAccount haproxy-service-account-datacenter under the same namespace.
3.	Create a ClusterRole which should be named as haproxy-cluster-role-datacenter, rules are placed under location /tmp/rules.yml on jump_host. 
Use the content of file /tmp/rules.yml to configure ClusterRole.
4.	Create a ClusterRoleBinding which should be named as haproxy-cluster-role-binding-datacenter under the same namespace. 
Define roleRef apiGroup should be rbac.authorization.k8s.io, kind should be ClusterRole, 
name should be haproxy-cluster-role-datacenter and subjects kind should be ServiceAccount, 
name should be haproxy-service-account-datacenter and namespace should be haproxy-controller-datacenter.
5.	Create a backend deployment which should be named as backend-deployment-datacenter under the same namespace, 
labels run should be ingress-default-backend under metadata. 
Configure spec as replica should be 1, selector's matchLabels run should be ingress-default-backend. 
Template's labels run under metadata should be ingress-default-backend. 
The container should named as backend-container-datacenter, 
use image gcr.io/google_containers/defaultbackend:1.0 ( use exact name of image as mentioned ) and its containerPort should be 8080.
6.	Create a service for backend which should be named as service-backend-datacenter under the same namespace, labels run should be ingress-default-backend. 
Configure spec as selector's run should beingress-default-backend, 
port should be named as port-backend, protocol should be TCP, port should be 8080 and targetPort should be 8080.
7.	Create a deployment for frontend which should be named as haproxy-ingress-datacenter under the same namespace. 
Configure spec as replica should be 1, selector's matchLabels should be haproxy-ingress, template's labels run should be haproxy-ingress under metadata. 
The container name should be ingress-container-datacenter under the same service account haproxy-service-account-datacenter, 
use image haproxytech/kubernetes-ingress, give args as --default-backend-service=haproxy-controller-datacenter/service-backend-datacenter, 
resources requests for cpu should be 500m and for memory should be 50Mi, livenessProbe httpGet path should be /healthz its port should be 1024. 
First port name should be http its containerPort should be 80, 
second port name should be https its containerPort should be 443 and third port name should be stat its containerPort should be 1024. 
Define environment as first env name should be TZ its value should be Etc/UTC, 
second env name should be POD_NAME its valueFrom fieldRef fieldPath should be metadata.name and third env name should be POD_NAMESPACE its valueFrom fieldRef fieldPath should be metadata.namespace.
8.	Create a service for frontend which should be named as ingress-service-datacenter under same namespace, 
labels run should be haproxy-ingress. Configure spec as selectors' run should be haproxy-ingress, type should be NodePort.
First port name should be http, its port should be 80, protocol should be TCP, targetPort should be 80 and nodePort should be 32456.
Second port name should be https, its port should be 443, protocol should be TCP, targetPort should be 443 and nodePort should be 32567. 
Third port name should be stat, its port should be 1024, protocol should be TCP, targetPort should be 1024 and nodePort should be 32678.

---
apiVersion: v1
kind: Namespace
metadata:
  name: haproxy-controller-datacenter

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: haproxy-service-account-datacenter
  namespace: haproxy-controller-datacenter

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  # "namespace" omitted since ClusterRoles are not namespaced
  name: haproxy-cluster-role-datacenter
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  - endpoints
  - nodes
  - pods
  - services
  - namespaces
  - events
  - serviceaccounts
  verbs:
  - get
  - list
  - watch
- apiGroups:  
  - "extensions"
  resources:
  - ingresses
  - ingresses/status
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: haproxy-cluster-role-binding-datacenter
  namespace: haproxy-controller-datacenter
subjects:
# You can specify more than one "subject"
- kind: ServiceAccount
  name: haproxy-service-account-datacenter # "name" is case sensitive
  namespace: haproxy-controller-datacenter
roleRef:
  # "roleRef" specifies the binding to a Role / ClusterRole
  kind: ClusterRole #this must be Role or ClusterRole
  name: haproxy-cluster-role-datacenter # this must match the name of the Role or ClusterRole you wish to bind to
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: apps/v1
kind: Deployment
metadata:
    name: backend-deployment-datacenter
    namespace: haproxy-controller-datacenter
    labels:
        run: ingress-default-backend
spec:
    replicas: 1
    selector:    
        matchLabels:
            run: ingress-default-backend
    template:
        metadata:
            labels:
                run: ingress-default-backend 
        spec:
            containers:
            - name: backend-container-datacenter
              image: gcr.io/google_containers/defaultbackend:1.0
              ports:
              - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
    name: service-backend-datacenter 
    namespace: haproxy-controller-datacenter
    labels:
        run: ingress-default-backend
spec:
    ports:
        - name: port-backend 
          targetPort: 8080
          port: 8080
          protocol: TCP
    selector:
        run: ingress-default-backend

---
apiVersion: apps/v1
kind: Deployment
metadata:
    name: haproxy-ingress-datacenter
    namespace: haproxy-controller-datacenter
    labels:
        run: haproxy-ingress
spec:
    replicas: 1
    selector:    
        matchLabels:
            run: haproxy-ingress
    template:
        metadata:
            labels:
                run: haproxy-ingress 
        spec:
            containers:
            - name: ingress-container-datacenter
              image: haproxytech/kubernetes-ingress
              args: ["--default-backend-service=haproxy-controller-datacenter/service-backend-datacenter"]
              resources:
                requests:
                  memory: "50Mi"
                  cpu: "500m"
              livenessProbe:
                httpGet:
                  path: /healthz
                  port: 1024
              ports:
              - name: http 
                containerPort: 80
              - name: https
                containerPort: 443
              - name: stat
                containerPort: 1024
              env:
              - name: TZ 
                value: "Etc/UTC"
              - name: POD_NAME
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.name
              - name: POD_NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
            serviceAccountName: haproxy-service-account-datacenter

---
apiVersion: v1
kind: Service
metadata:
    name: ingress-service-datacenter
    namespace: haproxy-controller-datacenter
    labels:
        run: haproxy-ingress
spec:
    ports:
        - name: http
          targetPort: 80
          port: 80
          nodePort: 32456
          protocol: TCP
        - name: https
          targetPort: 443
          port: 443
          nodePort: 32567
          protocol: TCP
        - name: stat
          targetPort: 1024
          port: 1024
          nodePort: 32678
          protocol: TCP
    type: NodePort
    selector:
        run: haproxy-ingress
        


